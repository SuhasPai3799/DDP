\documentclass[a4paper]{report}

\usepackage[a4paper,margin=3cm]{geometry}
\usepackage[utf8]{inputenc}
%\usepackage{times}
\usepackage[english]{babel}
\usepackage{multirow}
\usepackage{amsmath,graphicx}
\usepackage{natbib}
\usepackage{hyperref}
\usepackage{fancyvrb}
\usepackage[textwidth=2.5cm, textsize=small]{todonotes}
\usepackage{listings}
\lstset{% general command to set parameter(s)
  language=Java,
  basicstyle=\scriptsize,  % print whole listing small
  %keywordstyle=\color{black}\bfseries\underbar, % underlined bold black keywords
  %identifierstyle=,  % nothing happens
  %commentstyle=\color{white}, % white comments
  columns=fixed,
  basicstyle=\ttfamily,  % typewriter type for strings
  showstringspaces=false} % no special string spaces

\usepackage{xspace}
\newcommand{\vonda}{VOnDA\xspace}

\pgfdeclareimage[width=.99\columnwidth]{vondagui}{VondaGui}

\begin{document}

\title{\vonda, A Framework for Dialogue Management}

\author{Bernd Kiefer, Anna Welker}
\date{\today}

\maketitle

\tableofcontents

\chapter{Purpose}

\vonda is a framework to implement the dialogue management functionality in
dialogue systems. Although domain-independent, \vonda is tailored towards
dialogue systems with a focus on social communication, which implies the need
of a long-term memory and high user adaptivity. \vonda's specification and
memory layer relies upon (extended) RDF/OWL, which provides a universal and
uniform representation, and facilitates interoperability with external data
sources.

%\todo[inline]{Mention HFC and ref to appropriate section}
The RDF store and reasoner of choice used in \vonda is HFC
\citep{krieger2013efficient}. For further details about the general
funcitonalities of HFC see chapter \ref{sec:hfc}; for an example of HFC as a
database in a \vonda project please refer to section \ref{sec:example-hfc}.

\vonda consists of three parts: A programming language tailored towards the
specification of reactive rules and transparent RDF data store usage, a
compiler that turns source code in this language into Java code, and a run-time
core, that supports implementing dialogue management modules using the compiled
rules.

The framework is domain-independent, it was originally designed to for
multi-modal human-robot interaction, but there is currently no \emph{special}
functionality in the core to either support the multi-modality nor the
human-robot interaction. The architecture of the framework is open and powerful
enough to add these things easily.


\section{Internal Structure}

Figure \ref{fig:arch} shows the main components of a \vonda agent.


\begin{figure}[htb]
\includegraphics[width=.9\textwidth]{rudimant.png}
\caption{\label{fig:arch}Schematic \vonda agent}
\end{figure}

At the base there is an RDF store, which takes incoming sensor and interaction
data, and stores it as RDF data, based on a data specification in the form of
an ontology developed as part of the dialogue manager, making the data (via the
specification) available to all other components.

The dialogue manager will get several input types from the nexus, the ones
currently foreseen are: input from automatic speech recognition (ASR) or typed
natural input, user parameters, like name, age, hobbies, etc. but also more
dynamic ones like mood or health data, and also triggers from high-level
planning.

The second major component is the rule processor for the dialogue management
rules. The rules can not only use new data, but also the interaction history
stored in the RDF database to take their decisions.  When new data is added, a
set of declaratively specified reactive rules will propose dialogue moves or
other actions and send these proposals to the action selection mechanism. The
selection mechanism selects the ``best'' of the proposed actions and sends it
back. If the proposed action results in dialogue acts, these are turned into
verbal output and gestures with the help of a multimodal generation component,
which retrieves parameters from the RDF database to adapt the generation to the
user's likings, and can also take into account sensory data such as her or his
estimated mood.

The last two parts are a language interpretation module (not
explicitly shown in the picture), which turns spoken or written utterances
into dialogue acts, possibly with an intermediate step that involves a more
elaborate semantic format, and a multimodal generation component, which turns
outgoing dialogue acts into natural language utterances and gestures.

\chapter{Sketching a Simple Interaction Manager}

The simplest version of an interaction manager analyses natural language
coming from the user, and generates natural language and gestures for the robot
resp. its virtual replacement, the avatar. Generation is based on incoming
stimuli, like speech or text input, or high-level action requests coming from
some strategic planning component, or any other sensor input, if available.

In this tutorial, we will create a very simple example system that has a
database representation of itself and the user it will interact with. It can
greet the user, ask for their name and say goodbye.

To see the example system that is constructed in this chapter, switch to the
folder named examples. It contains the play-ground dialogue system
ChatCat. More complex examples are planned to be published soon.

\section{Setting up the RDF Store of your Project} \label{sec:example-hfc}

A dialogue system aiming for social interaction does need some kind of memory
representation. Therefore, the first step of building your dialogue manager
should be to set up the ontology. It can of course be extended on-the-fly,
while your system is becoming more and more elaborate, but you should still
create a base from which to start from.

At the very least, you are strongly recommended to use the dialogue hierarchy
(provided in \texttt{examples/chatcat/src/main/resources/ontology/dialogue.nt})
as well as two default information files pertaining to the dialogue acts used
in the \vonda framework.

\subsection{Creating n-Tuple Files}

%use Protege or another tool of your choice to create OWL/RDF file;
%example here: with Protege
HFC loads data from n-Tuple files. You can however create files in the more
common OWL format and then automatically transfer it with a simple shell
script, using the Raptor \citep{raptor}
(e.g. \texttt{examples/chatcat/ntcreate.sh}). This tutorial uses Protégé
\citep{Protege}.

Open your favourite IDE and create a new file that includes an RDF class Agent,
and two subclasses of this class, Robot and Human.

After that, create a predicate \texttt{name} for the class Agent that has its
range in \texttt{xsd:string}.

\begin{figure}
	\center
	    \begin{minipage}{0.45\textwidth}
		\centering
		\includegraphics[width=0.6\textwidth]{Images/doc_protege.png}
		%\caption{first figure}
	\end{minipage}\hfill
	\begin{minipage}{0.45\textwidth}
		\centering
		\includegraphics[width=0.6\textwidth]{Images/doc_protege2.png}
		%\caption{second figure}
	\end{minipage}
\end{figure}

As we do not know the user a priori, we will make the system create an instance
for them at run-time. However, we know our robot, so we will create an instance
of the class Robot and name it \textit{Robert}.

Now save your new ontology. Then you can use Raptor (i.e., the
\texttt{ntcreate.sh} script) to transform it into n-tuple format. Afterward,
create your \texttt{.ini}-file as described in the next section and add your
tuple file to it.

\textbf{Important:} If you are using Prot\'eg\'e, you should save the file in
RDF/XML Syntax; the script will not work otherwise.


\subsection{Combining multiple ontology files - How to Use the .ini}

%Explain how multiple ontologies can be put together here; explain PersistencyFile, mention what [Namespaces] is about
An HFC ontology is held together - and addressed to - via the ini file. This is
a plain text file with the ending \texttt{.ini} that contains various settings
and information. To create your own \texttt{.ini}, best copy the example below
and add your ontology information to it as described in the following
paragraphs.

\begin{figure} [htbp]
\begin{verbatim}
[Settings]
#minNoArgs=3
#maxNoArgs=4
#noAtoms=100000
#noTuples=500000
PersistencyFile=tuples.nt
Encoding=UTF-8

[Namespaces]
# namespaces for XSD, RDF, RDFS, and OWL are already defined
dial = http://www.dfki.de/lt/onto/common/dialogue.owl#
cat = http://www.semanticweb.org/anna/ontologies/2018/3/chatcat#

# instead, you can also load one or more namespace files
#default.ns

[Tuples]
# the axiomatic triples for OWL-Horst w/ EQ reduction
default.eqred.nt

[Tuples]
dialogue.nt
chatcat.nt

[Rules]
# we need special rules for transaction time (mixture of triples/quadruples)
default.eqred.quads.rdl
\end{verbatim}
\caption{An examplary \texttt{.ini} file}
\label{fig:ini}
\end{figure}

\paragraph{[Settings]}

For most applications concerning dialogue management, it will be important to
specify a \texttt{PersistencyFile}. You can put it anywhere you like (i.e., it
will be created automatically in the place you specify), but if your
application relies on inter-session memory, you probably don't want it to
reside in some temporary directory. All new information that your dialogue
system enters into the database will be collected here. So, if you want to find
out which specific tuples have just been entered, you can refer to this
file. At the same time, if you want to wipe the memory of your system, delete
this file.

\paragraph{[Namespaces]}

In this section, you can specify abbreviations for your ontology
namespaces. With the definition of the variable \texttt{dial} in figure
\ref{fig:ini}, it is made possible to refer to classes, predicates and
instances of this namespace with e.g. \texttt{<dial:Accept>} instead of\\
\texttt{<http://www.dfki.de/lt/onto/common/dialogue.owl\#Accept>} in your
queries to the database.

As you can see, we included a shortcut for our chatcat ontology here.

\paragraph{[Tuples]}

Here you can put all the ontology files that you created. You should also put
the file \texttt{dialogue.nt} which, as previously mentioned, contains the
specifications of the dialogue acts used by the \vonda framework.

\paragraph{[Rules]}

This specifies the set of rules that HFC uses to build the ontology. It is
recommended to simply use the file \texttt{default.eqred.quads.rdl} here. For
further information, please refer to the documentation of HFC.


\section{The Framework: Setting up the Base of your Dialogue System}

You need to implement your own abstract (Java) agent as a subclass of
\texttt{de.dfki.mlt.rudimant.agent.Agent}. Furthermore, you will need an
implementation of \texttt{de.dfki.mlt.rudimant.agent.CommunicationHub}. To see
an example of how this should be done, take a look in the source folder of
ChatCat.

The two most important things here are that you make sure that the database is
initialized (as an instance of RdfProxy) and that you do use an instance of
your \vonda Agent implementation in your client. Of course this code will not
compile until you build your first rule file, i.e., your \vonda Agent.

After this, the next thing you need is to create some main method where an
instance of your client is built and set running using the
\texttt{startListening()} method.

As a start, we recommend you to use the ChatCat system as a base for your own
system and extend it. This will also provide you with a GUI where you can test
your first dialogue steps.

\section{Connecting NLU and Generation Components}

%examplary here: srgs for NLU and cplan for generation
Basically, you can connect any NLU and NLG components to your project that are
able to create or, respectively, process dialogue acts of the format that
\vonda provides (cfg. \ref{sec:caret}).

For the sake of simplicity, this example uses SRGS to build a primitive NLU and
cplan to create natural language out of the dialogue acts the agent outputs.

\section{Writing some First Rules}

% how to react on an incoming greeting; ask for the user's name; create a new
% instance for the user if name is unknown or retrieve the correct instance
% from the database; also set a timeout for doing something afterwards
Now that everything else has been arranged, we are set up for writing our first
dialogue management rules.

So, let's react to the user greeting the system, what we expect to be happening
on startup. In the SRGS file (src/main/resources/grammars/srgs/chatcat.xml), we
defined that an utterance of the user like ''Hello'' will be parsed as the
dialogue act Salutation, with the proposition Greet. We now can define a rule
reacting to this utterance:

\begin{lstlisting}[language=Java]
greet_back:
  if (lastDA() <= #InitialGreeting(Greet)) {
  	user = new Human;
    propose("greet_back") {
      emitDA(#ReturnGreeting(Greet));
    }
    lastDAprocessed();
  }
\end{lstlisting}

This will create a new instance of Human, which is stored in a global variable
\verb|user| that in our case has been defined in the ChatAgent and will be
present during the whole conversation.

After greeting, we want to find out the user's name. We thus define a rule as
follows:

\begin{lstlisting}[language=Java]
ask_for_name:
  if (!user.name && !()myLastDA() <= #WHQuestion(Name))) {
    propose("ask_name") {
      emitDA(#WHQuestion(Name));
    }
    lastDAprocessed();
  }
\end{lstlisting}

And once we got the answer from the user, we can store this knowledge in the database:

\begin{lstlisting}[language=Java]
remember_name:
  if (lastDA() <= #Inform(Name)) {
    user.name = lastDA().what;
    lastDAprocessed();
  }
\end{lstlisting}

These are enough rules to start a conversation, so let's compile and try out
the new dialogue system.

\section{Specifying how to Compile and Run your Project}

You can compile your \vonda rule files by executing the command\\ \verb|<yourVondaDirectory>/compile -c <yourCompileYml> <YourToplevelRudiFile>|.

The compile.yml should contain the following parameters:\\

\begin{tabular}{ll}
	\verb|outputDirectory:| & Relative to the current location, where should the compiled classes go?\\
	\verb|wrapperClass:| & The name of your abstract Java Agent, fully qualified with package \\&specifcation\\
	\verb|ontologyFile:| &The path to your .ini, relative to the current location\\
	\verb|rootPackage:| &The package where you want the compile results to be in\\
	\verb|failOnError:| &Set to true to exit compilation on any encountered type errors,\\& otherwise set to false (*)\\
\end{tabular}\newline

(*) Note that although \vonda type checking is becoming more and more reliable,
it is not complete. In some cases, setting this switch to true might make your
project uncompilable although when compiling it when ignoring type errors would
result in a perfectly sound Java project.

To provide the possibility to easily change the Ontology, NLU and NLG
components of your project, it is recommended to create a second yml file
containing the following specifications (This is an example from ChatCat):

\begin{verbatim}
ontologyFile:       src/main/resources/ontology/chatcat.ini
NLG:
eng:
mapperProject: src/main/resources/grammars/cplanner/allrules-mapper
generationProject: src/main/resources/grammars/cplanner/allrules
NLU:
eng:
class: de.dfki.chatcat.SrgsParser
grammar: src/main/resources/grammars/srgs/chatcat.xml
\end{verbatim}

This configuration can then be easily read in when starting your project, and
be passed to the init method of Agent, which requires such information.

\subsection{Resolving Namespace Ambiguities}

As you might have noticed whilst looking at chatcat.yml, there is another
parameter used in the compile configuration of our example project:

\begin{verbatim}
	nameToURI:
	Agent : "<cat:Agent>"
\end{verbatim}

When trying to compile without these two lines, you will find that \vonda
produces the warning \begin{small}'' \texttt{base name Agent can be one of
    <http://www.semanticweb.org/anna/ontologies/2018/3/chatcat\#Agent>,
    <dial:Agent>, please resolve manually.}''
\end{small}.

This is the compiler telling us that when defining the Rdf class Agent in the
database step, we actually redefined an existing class. \vonda warns us about
this and urges us to resolve this ambiguity. Thus, we could either rename our
class, or explicitly state which namespace should be accessed whenever the
class Agent is used. \texttt{nameToURI} can be used to do the latter.

Of course, you can also use this functionality to ''rename'' Rdf classes as you
please: \vonda will always map the name on the left to the class URI provided
on the right.

\section{Advanced Features}

\subsection{Connecting to a second HFC Server}
% e.g., like for PAL, if loading (a passive part of) the database takes too much time to perform it for every test
In the standard setup, your \vonda project uses one HFC server that on starting your system loads all the information from your ontology and that receives your new database entries and modifications.

However, there might be cases where this approach is not what you want. If your project uses a big database with static information, that you use but do not need to write to, you might prefer to not start the server anew each time you start your system, as this might consume time (e.g., loading ???? WordNet\footnote{https://wordnet.princeton.edu/} triples takes ???\todo{numbers on PAL computer} minutes on a reasonably fast machine).


In this case, there is another solution: you can start your HFC server remotely and then connect to it in your \vonda agent.

\todo{hfc server start script}

\todo{code example adding new client and proxy for use in java}

This additional server does of course not have the same status as the innate HFC proxy, as you only connect to it at run-, not at compile-time. You can query it for information as described in \ref{hfc_usage}, but classes from this database will not be recognized in the rudi code and you cannot write to it \todo{or can you? Try?!}. 


\if0
%The multimodal interaction manager analyses natural language coming from the
%user, and generates natural language and gestures for the robot resp. its
%virtual replacement, the avatar. The generation is based on incoming stimuli,
%like speech or text input, or high-level action requests coming from some
%strategic planning component, or any other sensor input, if available.
%
%The goal is to create engaging interactions with the users that support the
%currently active high-level goals.
Natural language dialogue systems are becoming more and more popular, be it as
virtual assistants such as Siri or Cortana, as Chat Bots on websites providing
customer support, or as interface in human-robot interactions in areas ranging
from Industry 4.0 \citep{schwartz2016hybrid} over social human-robot-interaction
\citep{alize2010} to disaster response \citep{kruijff2015tradr}.

A central component of most systems is the \emph{dialogue manager}, which
controls the (possibly multi-modal) reactions based on sensory input and the
current system state. The existing frameworks to implement dialogue management
components roughly fall into two big groups, those that use symbolic
information or automata to specify the dialogue flow (IrisTK
\citep{2012iristk}, RavenClaw \citep{bohus2009ravenclaw}, Visual SceneMaker
\citep{gebhard2012visual}), and those that mostly use statistical methods
(PyDial \cite{ultes2017pydial}, Alex \citep{jurvcivcek2014alex}). Somewhat in
between these is OpenDial \citep{lison2015developing}, which builds on
probabilistic rules and a Bayesian Network.

When building dialogue components for robotic systems or in-car assistants, the system
needs to take into account \emph{various} system inputs, first and foremost the
user utterances, but also other sensoric input that may influence the dialogue,
such as information from computer vision, gaze detection, or even body and
environment sensors for cognitive load estimation.

The integration and handling of the different sources such that all data is
easily accessible to the dialogue management is by no means trivial. Most
frameworks use plug-ins that directly interface to the dialogue core. The
multi-modal dialogue platform SiAM-dp \citep{nesselrath2014siam}
addresses this in a more fundamental way using a modeling approach that allows
to share variables or objects between different modules.

In the application domain of social robotic assistants, it is vital to be able
to maintain a relationship with the user over a longer time period. This requires a long-term
memory which can be used in the dialogue system to exhibit familiarity with the
user in various aspects, like personal preferences, but also common knowledge
about past conversations or events, ranging over multiple sessions.

In the following, we will describe \vonda, an open-source framework to
implement dialogue strategies. It follows the information state/update
tradition \citep{traum2003information}
%DR Traum, S Larsson. The information state approach to dialogue management. In: Current and new directions in discourse and dialogue, 2003, pp.  325-353. Kluwer.
combining a rule-based approach with statistical selection, although in a
different way than OpenDial. \vonda specifically targets the following design
goals to support the system requirements described before:

\begin{itemize}
  \addtolength{\itemsep}{-.6\itemsep}
\item Flexible and uniform specification of dialogue semantics, knowledge and
  data structures
\item Scalable, efficient, and easily accessible storage of interaction history
  and other data, resulting in a large information state
\item Readable and compact rule specifications, facilitating access to the
  underlying RDF database, with the full power of a programming language
\item Transparent access to Java classes for simple integration with the host
  system
\end{itemize}
\fi
%\chapter{Interaction with the overall system}



%\input{design}

\chapter{Installing and Getting Started}

\input{system}
\newpage
\input{debugger}
\newpage
\input{hfc}

% implementation patterns and caveats
\chapter{Building VOnDA Agents}
\input{patterns}
\newpage
\input{caveats}
\newpage
% and maybe tips and tricks?

\bibliography{vonda}
\bibliographystyle{apa}

\end{document}
